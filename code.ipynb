{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 16:48:46.681021: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-12 16:48:46.681048: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-12 16:48:46.681476: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-12 16:48:46.727322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 16:48:47.504584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/hs/anaconda3/envs/temp2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# conv, group conv, separable conv, depth wise conv, point wise conv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Conv2D, SeparableConv2D, DepthwiseConv2D, BatchNormalization, ReLU, GlobalAveragePooling2D, Flatten, Dense, MaxPool2D\n",
    "from tensorflow.keras import Sequential, Model\n",
    "import tensorflow_datasets as tfds\n",
    "import tqdm, os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 16:48:48.506852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:48.584931: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:48.585115: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:48.586222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:48.586372: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:48.586508: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:49.202198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:49.202357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:49.202497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-12 16:48:49.202684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21387 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:0e:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "ic, oc = 20, 30\n",
    "g = 10\n",
    "input = tf.zeros([1, 20, 20, ic])\n",
    "conv = Conv2D(oc, [3,3], padding='same') # normal\n",
    "g_conv = Conv2D(oc, [3,3], groups=g, padding='same') # group\n",
    "s_conv = SeparableConv2D(oc, (3,3), padding='same') # depth wise & point wise\n",
    "d_conv = DepthwiseConv2D((3,3), padding='same') # depth wise\n",
    "p_conv = Conv2D(oc, [1,1]) # point wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 16:48:50.536844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (1, 20, 20, 30)           5430      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5430 (21.21 KB)\n",
      "Trainable params: 5430 (21.21 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 20, 20, 30]), None, 5430)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([conv])\n",
    "model(input).shape, model.summary(), 3**2*ic*oc+oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (1, 20, 20, 30)           570       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 570 (2.23 KB)\n",
      "Trainable params: 570 (2.23 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 16:48:51.368140: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c807aabe480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-04-12 16:48:51.368169: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-04-12 16:48:51.535398: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 20, 20, 30]), None, 570)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([g_conv])\n",
    "model(input).shape, model.summary(), (3**2*ic*oc)//g+oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " separable_conv2d (Separabl  (1, 20, 20, 30)           810       \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 810 (3.16 KB)\n",
      "Trainable params: 810 (3.16 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 20, 20, 30]), None, 810)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([s_conv])\n",
    "model(input).shape, model.summary(), 3**2*ic + ic*oc+oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " depthwise_conv2d (Depthwis  (1, 20, 20, 20)           200       \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 200 (800.00 Byte)\n",
      "Trainable params: 200 (800.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 20, 20, 20]), None, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([d_conv])\n",
    "model(input).shape, model.summary(), 3**2*ic+ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " depthwise_conv2d (Depthwis  (1, 20, 20, 20)           200       \n",
      " eConv2D)                                                        \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (1, 20, 20, 30)           630       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 830 (3.24 KB)\n",
      "Trainable params: 830 (3.24 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 20, 20, 30]), None, 830)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([d_conv, p_conv])\n",
    "model(input).shape, model.summary(), 3**2*ic+ic + ic*oc+oc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "bias = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "\n",
    "class CBA(Layer):\n",
    "    def __init__(self, conv, oc, kernel, groups=1, strides=(1,1), padding='same', bn=True, act=True):\n",
    "        super().__init__()\n",
    "        if conv == SeparableConv2D:\n",
    "            self.conv = conv(oc, kernel, strides=strides, padding=padding, kernel_initializer=weights, bias_initializer=bias)\n",
    "        else:\n",
    "            self.conv = conv(oc, kernel, groups=groups, strides=strides, padding=padding, kernel_initializer=weights, bias_initializer=bias)\n",
    "        self.bn = BatchNormalization() if bn else Identity()\n",
    "        self.act = ReLU() if act else Identity()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x, training)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Identity(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        return x\n",
    "\n",
    "    def train(self, x, arg=False):\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResBlock(Layer):\n",
    "    def __init__(self, conv, oc, kernel, groups=1, strides=1, padding='same'):\n",
    "        super().__init__()\n",
    "        self.conv1 = CBA(conv, oc, kernel, groups=groups, strides=strides, padding=padding)\n",
    "        self.conv2 = CBA(conv, oc, kernel, groups=groups, strides=1, padding=padding, act=False)\n",
    "        self.res_conv = CBA(conv, oc, 1, groups=groups, strides=strides, padding=padding, act=False) if strides != 1 else Identity()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        residual = self.res_conv(x, training)\n",
    "        x = self.conv1(x, training)\n",
    "        x = self.conv2(x, training)\n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class ResNet18(Model):\n",
    "    def __init__(self, conv, g, oc, nc):\n",
    "        super().__init__()\n",
    "        if conv == Conv2D:\n",
    "            if g == 1:\n",
    "                self.conv_name = 'Conv'\n",
    "            else:\n",
    "                self.conv_name = 'GroupConv'\n",
    "        elif conv == SeparableConv2D:\n",
    "            self.conv_name = 'SeparableConv'\n",
    "        self.oc = oc\n",
    "\n",
    "        self.conv = CBA(conv, oc, 7, g, (2,2), 'same')\n",
    "        self.maxpool = MaxPool2D((3,3), strides=(2,2), padding='same')\n",
    "        g = oc if g != 1 else 1\n",
    "\n",
    "        self.res1 = [ResBlock(conv, oc, 3, g, 1, 'same'),\n",
    "                     ResBlock(conv, oc, 3, g, 1, 'same')]\n",
    "        g = oc if g != 1 else 1\n",
    "\n",
    "        self.res2 = [ResBlock(conv, oc*2, 3, g, 2, 'same'),\n",
    "                     ResBlock(conv, oc*2, 3, g, 1, 'same')]\n",
    "        g = oc*2 if g != 1 else 1\n",
    "\n",
    "\n",
    "        self.res3 = [ResBlock(conv, oc*4, 3, g, 2, 'same'),\n",
    "                     ResBlock(conv, oc*4, 3, g, 1, 'same')]\n",
    "        g = oc*4 if g != 1 else 1\n",
    "\n",
    "        self.res4 = [ResBlock(conv, oc*8, 3, g, 2, 'same'),\n",
    "                     ResBlock(conv, oc*8, 3, g, 1, 'same')]\n",
    "\n",
    "        self.gap = GlobalAveragePooling2D()\n",
    "        self.flatten = Flatten()\n",
    "        self.linear = Dense(nc, kernel_initializer=weights, bias_initializer=bias)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv(x, training)\n",
    "        x = self.maxpool(x)\n",
    "        for res in self.res1:\n",
    "            x = res(x, training)\n",
    "        for res in self.res2:\n",
    "            x = res(x, training)\n",
    "        for res in self.res3:\n",
    "            x = res(x, training)\n",
    "        for res in self.res4:\n",
    "            x = res(x, training)\n",
    "        x = self.gap(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_padding(image, random=False, mode='CONSTANT', constant_values=0, seed=42):\n",
    "    size = tf.cast(tf.shape(image)[:2][::-1], tf.float32)\n",
    "    ratio = img_size/tf.reduce_max(size)\n",
    "    new_size = tf.cast(ratio * size, tf.int32)\n",
    "    pad_size = img_size - tf.cast(new_size, tf.float32)\n",
    "\n",
    "    pad_ratio = tf.random.uniform((), 0, 1, seed=seed) if random else 0.5\n",
    "    pad_LT = tf.cast(pad_size*pad_ratio, tf.int32)\n",
    "    pad_RB = tf.cast(pad_size, tf.int32) - pad_LT\n",
    "    pad_left, pad_top = tf.unstack(pad_LT)\n",
    "    pad_right, pad_bottom = tf.unstack(pad_RB)\n",
    "    padding = tf.reshape(tf.stack([pad_top, pad_bottom, pad_left, pad_right, 0, 0]), [3, 2])\n",
    "\n",
    "    resized_image = tf.image.resize(image, new_size[::-1])\n",
    "    padded_image = tf.pad(resized_image, padding, mode=mode, constant_values=constant_values)\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def preprocessing(name, image, label):\n",
    "    if name == 'mnist':\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "    image = resize_padding(image)\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "def get_data(name):\n",
    "    data, info = tfds.load(name, with_info=True, as_supervised=True, data_dir='./data')\n",
    "    train_data = data['train']\n",
    "    train_data = train_data.map(lambda x, y: preprocessing(name, x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True, num_parallel_calls=-1).cache().shuffle(60000).prefetch(tf.data.AUTOTUNE)\n",
    "    test_data = data['test']\n",
    "    test_data = test_data.map(lambda x, y: preprocessing(name, x, y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True, num_parallel_calls=-1).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "def get_opt_loss(lr):\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    return optimizer, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(data, model):\n",
    "    def train():\n",
    "        optimizer, loss = get_opt_loss(lr)\n",
    "        @tf.function\n",
    "        def train_step(x, y):\n",
    "            with tf.GradientTape() as train_tape:\n",
    "                preds = model(x, True)\n",
    "                loss_ = loss(y, preds)\n",
    "                gradients = train_tape.gradient(loss_, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "            return loss_\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_tqdm = tqdm.tqdm(train_data, total=len(train_data), desc=f'train {model.conv_name} epoch {epoch+1}/{epochs}', ascii=' =', colour='red')\n",
    "            total_loss = 0\n",
    "            if epoch < 400:\n",
    "                optimizer.lr.assign(lr)\n",
    "            elif epoch < 70:\n",
    "                optimizer.lr.assign(lr*1e-1)\n",
    "            elif epoch < 90:\n",
    "                optimizer.lr.assign(lr*1e-2)\n",
    "            else:\n",
    "                optimizer.lr.assign(lr*1e-3)\n",
    "            for iter, (images, labels) in enumerate(train_tqdm):\n",
    "                loss_ = train_step(images, labels)\n",
    "                total_loss += loss_\n",
    "                loss_ = total_loss / (iter+1)\n",
    "                train_tqdm.set_postfix_str(f'lr={optimizer.lr.numpy():.4f}, loss={loss_.numpy():.5f}')\n",
    "\n",
    "    def test():\n",
    "        correct = 0\n",
    "        pred_time = 0\n",
    "\n",
    "        @tf.function\n",
    "        def test_step(x):\n",
    "            preds = model(x)\n",
    "            return preds\n",
    "\n",
    "        test_tqdm = tqdm.tqdm(test_data, total=len(test_data), desc=f'test {model.conv_name} ', ascii=' =', colour='blue')\n",
    "        for iter, (images, labels) in enumerate(test_tqdm):\n",
    "            st = tf.timestamp()\n",
    "            preds = test_step(images)\n",
    "            et = tf.timestamp()\n",
    "            pred_time += (et - st)\n",
    "\n",
    "            correct += tf.reduce_sum(tf.cast(labels==tf.argmax(preds, -1), tf.int32))\n",
    "            test_tqdm.set_postfix_str(f'correct: {correct}/{(iter+1)*labels.shape[0]}, time: {pred_time/(iter+1):.5f}')\n",
    "\n",
    "    train_data, test_data = get_data(data)\n",
    "    train()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "Model: \"res_net18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cba (CBA)                   multiple                  456       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " res_block (ResBlock)        multiple                  192       \n",
      "                                                                 \n",
      " res_block_1 (ResBlock)      multiple                  192       \n",
      "                                                                 \n",
      " res_block_2 (ResBlock)      multiple                  594       \n",
      "                                                                 \n",
      " res_block_3 (ResBlock)      multiple                  708       \n",
      "                                                                 \n",
      " res_block_4 (ResBlock)      multiple                  2196      \n",
      "                                                                 \n",
      " res_block_5 (ResBlock)      multiple                  2712      \n",
      "                                                                 \n",
      " res_block_6 (ResBlock)      multiple                  8424      \n",
      "                                                                 \n",
      " res_block_7 (ResBlock)      multiple                  10608     \n",
      "                                                                 \n",
      " global_average_pooling2d (  multiple                  0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  250       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26332 (102.86 KB)\n",
      "Trainable params: 25882 (101.10 KB)\n",
      "Non-trainable params: 450 (1.76 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Conv epoch 1/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:06<00:00,  4.70it/s, lr=0.1000, loss=0.93802]\n",
      "train Conv epoch 2/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.64it/s, lr=0.1000, loss=0.28475]\n",
      "train Conv epoch 3/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.28it/s, lr=0.1000, loss=0.19797]\n",
      "train Conv epoch 4/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.55it/s, lr=0.1000, loss=0.15710]\n",
      "train Conv epoch 5/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.96it/s, lr=0.1000, loss=0.13150]\n",
      "train Conv epoch 6/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:00<00:00, 30.02it/s, lr=0.1000, loss=0.11566]\n",
      "train Conv epoch 7/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.92it/s, lr=0.1000, loss=0.10307]\n",
      "train Conv epoch 8/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.93it/s, lr=0.1000, loss=0.09367]\n",
      "train Conv epoch 9/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.92it/s, lr=0.1000, loss=0.08507]\n",
      "train Conv epoch 10/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.67it/s, lr=0.1000, loss=0.07899]\n",
      "train Conv epoch 11/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:00<00:00, 30.06it/s, lr=0.1000, loss=0.07324]\n",
      "train Conv epoch 12/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:00<00:00, 30.04it/s, lr=0.1000, loss=0.06931]\n",
      "train Conv epoch 13/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:00<00:00, 30.17it/s, lr=0.1000, loss=0.06470]\n",
      "train Conv epoch 14/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:00<00:00, 30.10it/s, lr=0.1000, loss=0.06118]\n",
      "train Conv epoch 15/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.66it/s, lr=0.1000, loss=0.05804]\n",
      "train Conv epoch 16/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.94it/s, lr=0.1000, loss=0.05498]\n",
      "train Conv epoch 17/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.93it/s, lr=0.1000, loss=0.05255]\n",
      "train Conv epoch 18/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:00<00:00, 30.06it/s, lr=0.1000, loss=0.05024]\n",
      "train Conv epoch 19/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.85it/s, lr=0.1000, loss=0.04796]\n",
      "train Conv epoch 20/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 29.47it/s, lr=0.1000, loss=0.04591]\n",
      "test Conv : 100%|\u001b[34m==========\u001b[0m| 5/5 [00:00<00:00,  7.26it/s, correct: 9800/10000, time: 0.10573]\n"
     ]
    }
   ],
   "source": [
    "data = 'mnist'\n",
    "img_size = 64\n",
    "epochs = 20\n",
    "batch_size = 2000\n",
    "lr=1e-1\n",
    "\n",
    "oc, nc, ic = 3, 10, 3\n",
    "g = 1\n",
    "input = tf.zeros([1, 64, 64, ic])\n",
    "conv = Conv2D\n",
    "s_conv = SeparableConv2D\n",
    "\n",
    "model = ResNet18(conv, g, oc, nc)\n",
    "print(model(input).shape)\n",
    "model.summary()\n",
    "train_test(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "Model: \"res_net18_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cba_20 (CBA)                multiple                  171       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " res_block_8 (ResBlock)      multiple                  102       \n",
      "                                                                 \n",
      " res_block_9 (ResBlock)      multiple                  102       \n",
      "                                                                 \n",
      " res_block_10 (ResBlock)     multiple                  246       \n",
      "                                                                 \n",
      " res_block_11 (ResBlock)     multiple                  240       \n",
      "                                                                 \n",
      " res_block_12 (ResBlock)     multiple                  636       \n",
      "                                                                 \n",
      " res_block_13 (ResBlock)     multiple                  624       \n",
      "                                                                 \n",
      " res_block_14 (ResBlock)     multiple                  1848      \n",
      "                                                                 \n",
      " res_block_15 (ResBlock)     multiple                  1824      \n",
      "                                                                 \n",
      " global_average_pooling2d_1  multiple                  0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  250       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6043 (23.61 KB)\n",
      "Trainable params: 5593 (21.85 KB)\n",
      "Non-trainable params: 450 (1.76 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train SeparableConv epoch 1/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:06<00:00,  4.88it/s, lr=0.1000, loss=1.18659]\n",
      "train SeparableConv epoch 2/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.81it/s, lr=0.1000, loss=0.41193]\n",
      "train SeparableConv epoch 3/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.00it/s, lr=0.1000, loss=0.29024]\n",
      "train SeparableConv epoch 4/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.79it/s, lr=0.1000, loss=0.22649]\n",
      "train SeparableConv epoch 5/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.99it/s, lr=0.1000, loss=0.18032]\n",
      "train SeparableConv epoch 6/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.24it/s, lr=0.1000, loss=0.15793]\n",
      "train SeparableConv epoch 7/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.95it/s, lr=0.1000, loss=0.14246]\n",
      "train SeparableConv epoch 8/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.96it/s, lr=0.1000, loss=0.12323]\n",
      "train SeparableConv epoch 9/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.19it/s, lr=0.1000, loss=0.11860]\n",
      "train SeparableConv epoch 10/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.08it/s, lr=0.1000, loss=0.10555]\n",
      "train SeparableConv epoch 11/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.11it/s, lr=0.1000, loss=0.10327]\n",
      "train SeparableConv epoch 12/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.14it/s, lr=0.1000, loss=0.09348]\n",
      "train SeparableConv epoch 13/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.92it/s, lr=0.1000, loss=0.08952]\n",
      "train SeparableConv epoch 14/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.11it/s, lr=0.1000, loss=0.08950]\n",
      "train SeparableConv epoch 15/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.01it/s, lr=0.1000, loss=0.08111]\n",
      "train SeparableConv epoch 16/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.86it/s, lr=0.1000, loss=0.07935]\n",
      "train SeparableConv epoch 17/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.17it/s, lr=0.1000, loss=0.07587]\n",
      "train SeparableConv epoch 18/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.10it/s, lr=0.1000, loss=0.07377]\n",
      "train SeparableConv epoch 19/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 23.93it/s, lr=0.1000, loss=0.07132]\n",
      "train SeparableConv epoch 20/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 24.19it/s, lr=0.1000, loss=0.06905]\n",
      "test SeparableConv : 100%|\u001b[34m==========\u001b[0m| 5/5 [00:00<00:00, 11.51it/s, correct: 9667/10000, time: 0.06144]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(s_conv, g, oc, nc)\n",
    "print(model(input).shape)\n",
    "model.summary()\n",
    "train_test(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x79f00c50c940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Conv._jit_compiled_convolution_op at 0x79f00c50c940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x79f0b299ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Conv._jit_compiled_convolution_op at 0x79f0b299ab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10)\n",
      "Model: \"res_net18_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cba_40 (CBA)                multiple                  162       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " res_block_16 (ResBlock)     multiple                  84        \n",
      "                                                                 \n",
      " res_block_17 (ResBlock)     multiple                  84        \n",
      "                                                                 \n",
      " res_block_18 (ResBlock)     multiple                  258       \n",
      "                                                                 \n",
      " res_block_19 (ResBlock)     multiple                  276       \n",
      "                                                                 \n",
      " res_block_20 (ResBlock)     multiple                  516       \n",
      "                                                                 \n",
      " res_block_21 (ResBlock)     multiple                  552       \n",
      "                                                                 \n",
      " res_block_22 (ResBlock)     multiple                  1032      \n",
      "                                                                 \n",
      " res_block_23 (ResBlock)     multiple                  1104      \n",
      "                                                                 \n",
      " global_average_pooling2d_2  multiple                  0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  250       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4318 (16.87 KB)\n",
      "Trainable params: 3868 (15.11 KB)\n",
      "Non-trainable params: 450 (1.76 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train GroupConv epoch 1/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:11<00:00,  2.69it/s, lr=0.1000, loss=1.16695]\n",
      "train GroupConv epoch 2/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.59it/s, lr=0.1000, loss=0.47793]\n",
      "train GroupConv epoch 3/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.73it/s, lr=0.1000, loss=0.33630]\n",
      "train GroupConv epoch 4/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.68it/s, lr=0.1000, loss=0.27142]\n",
      "train GroupConv epoch 5/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.56it/s, lr=0.1000, loss=0.23105]\n",
      "train GroupConv epoch 6/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.88it/s, lr=0.1000, loss=0.20447]\n",
      "train GroupConv epoch 7/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.55it/s, lr=0.1000, loss=0.18505]\n",
      "train GroupConv epoch 8/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.77it/s, lr=0.1000, loss=0.17118]\n",
      "train GroupConv epoch 9/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.75it/s, lr=0.1000, loss=0.15906]\n",
      "train GroupConv epoch 10/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.70it/s, lr=0.1000, loss=0.14922]\n",
      "train GroupConv epoch 11/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.77it/s, lr=0.1000, loss=0.14116]\n",
      "train GroupConv epoch 12/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.82it/s, lr=0.1000, loss=0.13434]\n",
      "train GroupConv epoch 13/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.85it/s, lr=0.1000, loss=0.12852]\n",
      "train GroupConv epoch 14/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.69it/s, lr=0.1000, loss=0.12341]\n",
      "train GroupConv epoch 15/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.81it/s, lr=0.1000, loss=0.11826]\n",
      "train GroupConv epoch 16/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.89it/s, lr=0.1000, loss=0.11563]\n",
      "train GroupConv epoch 17/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.86it/s, lr=0.1000, loss=0.11217]\n",
      "train GroupConv epoch 18/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.68it/s, lr=0.1000, loss=0.10796]\n",
      "train GroupConv epoch 19/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.76it/s, lr=0.1000, loss=0.10512]\n",
      "train GroupConv epoch 20/20: 100%|\u001b[31m==========\u001b[0m| 30/30 [00:01<00:00, 25.53it/s, lr=0.1000, loss=0.10221]\n",
      "test GroupConv : 100%|\u001b[34m==========\u001b[0m| 5/5 [00:00<00:00,  6.11it/s, correct: 9632/10000, time: 0.13944]\n"
     ]
    }
   ],
   "source": [
    "g=3\n",
    "model = ResNet18(conv, g, oc, nc)\n",
    "print(model(input).shape)\n",
    "model.summary()\n",
    "train_test(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "Model: \"res_net18_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cba_60 (CBA)                multiple                  9120      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " res_block_24 (ResBlock)     multiple                  65400     \n",
      "                                                                 \n",
      " res_block_25 (ResBlock)     multiple                  65400     \n",
      "                                                                 \n",
      " res_block_26 (ResBlock)     multiple                  203400    \n",
      "                                                                 \n",
      " res_block_27 (ResBlock)     multiple                  260400    \n",
      "                                                                 \n",
      " res_block_28 (ResBlock)     multiple                  810000    \n",
      "                                                                 \n",
      " res_block_29 (ResBlock)     multiple                  1039200   \n",
      "                                                                 \n",
      " res_block_30 (ResBlock)     multiple                  3232800   \n",
      "                                                                 \n",
      " res_block_31 (ResBlock)     multiple                  4152000   \n",
      "                                                                 \n",
      " global_average_pooling2d_3  multiple                  0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  48100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9885820 (37.71 MB)\n",
      "Trainable params: 9876820 (37.68 MB)\n",
      "Non-trainable params: 9000 (35.16 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train Conv epoch 1/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:05<00:00,  3.84it/s, lr=0.1000, loss=3.96783]\n",
      "train Conv epoch 2/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.96it/s, lr=0.1000, loss=3.16660]\n",
      "train Conv epoch 3/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.94it/s, lr=0.1000, loss=2.68130]\n",
      "train Conv epoch 4/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.91it/s, lr=0.1000, loss=2.26066]\n",
      "train Conv epoch 5/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.94it/s, lr=0.1000, loss=1.94629]\n",
      "train Conv epoch 6/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.94it/s, lr=0.1000, loss=1.69020]\n",
      "train Conv epoch 7/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.95it/s, lr=0.1000, loss=1.47368]\n",
      "train Conv epoch 8/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.92it/s, lr=0.1000, loss=1.27575]\n",
      "train Conv epoch 9/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.91it/s, lr=0.1000, loss=1.07531]\n",
      "train Conv epoch 10/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.93it/s, lr=0.1000, loss=0.88215]\n",
      "train Conv epoch 11/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.91it/s, lr=0.1000, loss=0.68945]\n",
      "train Conv epoch 12/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.91it/s, lr=0.1000, loss=0.49166]\n",
      "train Conv epoch 13/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.96it/s, lr=0.1000, loss=0.30280]\n",
      "train Conv epoch 14/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.97it/s, lr=0.1000, loss=0.14726]\n",
      "train Conv epoch 15/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.89it/s, lr=0.1000, loss=0.06082]\n",
      "train Conv epoch 16/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.87it/s, lr=0.1000, loss=0.02998]\n",
      "train Conv epoch 17/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.87it/s, lr=0.1000, loss=0.01735]\n",
      "train Conv epoch 18/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.89it/s, lr=0.1000, loss=0.01335]\n",
      "train Conv epoch 19/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:50<00:00,  4.91it/s, lr=0.1000, loss=0.01119]\n",
      "train Conv epoch 20/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.88it/s, lr=0.1000, loss=0.00933]\n",
      "train Conv epoch 21/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.84it/s, lr=0.1000, loss=0.00772]\n",
      "train Conv epoch 22/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.87it/s, lr=0.1000, loss=0.00680]\n",
      "train Conv epoch 23/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.88it/s, lr=0.1000, loss=0.00692]\n",
      "train Conv epoch 24/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.86it/s, lr=0.1000, loss=0.00584]\n",
      "train Conv epoch 25/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.89it/s, lr=0.1000, loss=0.00605]\n",
      "train Conv epoch 26/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.88it/s, lr=0.1000, loss=0.00484]\n",
      "train Conv epoch 27/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.88it/s, lr=0.1000, loss=0.00505]\n",
      "train Conv epoch 28/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.89it/s, lr=0.1000, loss=0.00492]\n",
      "train Conv epoch 29/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.89it/s, lr=0.1000, loss=0.00473]\n",
      "train Conv epoch 30/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.90it/s, lr=0.1000, loss=0.00415]\n",
      "test Conv : 100%|\u001b[34m==========\u001b[0m| 50/50 [00:07<00:00,  6.38it/s, correct: 5910/10000, time: 0.06844]\n"
     ]
    }
   ],
   "source": [
    "data = 'cifar100'\n",
    "img_size = 256\n",
    "epochs = 30\n",
    "batch_size = 200\n",
    "lr=1e-1\n",
    "\n",
    "oc, nc, ic = 60, 100, 3\n",
    "g = 1\n",
    "input = tf.zeros([1, 64, 64, ic])\n",
    "conv = Conv2D\n",
    "s_conv = SeparableConv2D\n",
    "\n",
    "model = ResNet18(conv, g, oc, nc)\n",
    "print(model(input).shape)\n",
    "model.summary()\n",
    "train_test(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "Model: \"res_net18_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cba_80 (CBA)                multiple                  627       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " res_block_32 (ResBlock)     multiple                  8880      \n",
      "                                                                 \n",
      " res_block_33 (ResBlock)     multiple                  8880      \n",
      "                                                                 \n",
      " res_block_34 (ResBlock)     multiple                  32280     \n",
      "                                                                 \n",
      " res_block_35 (ResBlock)     multiple                  32160     \n",
      "                                                                 \n",
      " res_block_36 (ResBlock)     multiple                  122160    \n",
      "                                                                 \n",
      " res_block_37 (ResBlock)     multiple                  121920    \n",
      "                                                                 \n",
      " res_block_38 (ResBlock)     multiple                  474720    \n",
      "                                                                 \n",
      " res_block_39 (ResBlock)     multiple                  474240    \n",
      "                                                                 \n",
      " global_average_pooling2d_4  multiple                  0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             multiple                  48100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1323967 (5.05 MB)\n",
      "Trainable params: 1314967 (5.02 MB)\n",
      "Non-trainable params: 9000 (35.16 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train SeparableConv epoch 1/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:51<00:00,  4.84it/s, lr=0.1000, loss=3.73434]\n",
      "train SeparableConv epoch 2/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.61it/s, lr=0.1000, loss=2.94048]\n",
      "train SeparableConv epoch 3/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.54it/s, lr=0.1000, loss=2.50649]\n",
      "train SeparableConv epoch 4/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.57it/s, lr=0.1000, loss=2.20234]\n",
      "train SeparableConv epoch 5/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.60it/s, lr=0.1000, loss=1.97437]\n",
      "train SeparableConv epoch 6/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.59it/s, lr=0.1000, loss=1.78593]\n",
      "train SeparableConv epoch 7/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.58it/s, lr=0.1000, loss=1.62618]\n",
      "train SeparableConv epoch 8/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.59it/s, lr=0.1000, loss=1.48229]\n",
      "train SeparableConv epoch 9/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.62it/s, lr=0.1000, loss=1.35871]\n",
      "train SeparableConv epoch 10/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.61it/s, lr=0.1000, loss=1.22695]\n",
      "train SeparableConv epoch 11/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.59it/s, lr=0.1000, loss=1.10507]\n",
      "train SeparableConv epoch 12/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.57it/s, lr=0.1000, loss=0.98921]\n",
      "train SeparableConv epoch 13/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.60it/s, lr=0.1000, loss=0.87104]\n",
      "train SeparableConv epoch 14/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.59it/s, lr=0.1000, loss=0.75978]\n",
      "train SeparableConv epoch 15/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.60it/s, lr=0.1000, loss=0.64791]\n",
      "train SeparableConv epoch 16/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.61it/s, lr=0.1000, loss=0.54125]\n",
      "train SeparableConv epoch 17/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.62it/s, lr=0.1000, loss=0.43601]\n",
      "train SeparableConv epoch 18/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.58it/s, lr=0.1000, loss=0.33356]\n",
      "train SeparableConv epoch 19/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.56it/s, lr=0.1000, loss=0.23789]\n",
      "train SeparableConv epoch 20/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.58it/s, lr=0.1000, loss=0.15249]\n",
      "train SeparableConv epoch 21/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.58it/s, lr=0.1000, loss=0.08945]\n",
      "train SeparableConv epoch 22/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.58it/s, lr=0.1000, loss=0.04994]\n",
      "train SeparableConv epoch 23/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.58it/s, lr=0.1000, loss=0.03162]\n",
      "train SeparableConv epoch 24/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.61it/s, lr=0.1000, loss=0.02334]\n",
      "train SeparableConv epoch 25/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.64it/s, lr=0.1000, loss=0.01853]\n",
      "train SeparableConv epoch 26/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.64it/s, lr=0.1000, loss=0.01540]\n",
      "train SeparableConv epoch 27/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.59it/s, lr=0.1000, loss=0.01474]\n",
      "train SeparableConv epoch 28/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.58it/s, lr=0.1000, loss=0.01305]\n",
      "train SeparableConv epoch 29/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:37<00:00,  6.60it/s, lr=0.1000, loss=0.01185]\n",
      "train SeparableConv epoch 30/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [00:38<00:00,  6.57it/s, lr=0.1000, loss=0.01083]\n",
      "test SeparableConv : 100%|\u001b[34m==========\u001b[0m| 50/50 [00:04<00:00, 11.23it/s, correct: 5417/10000, time: 0.04423]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(s_conv, g, oc, nc)\n",
    "print(model(input).shape)\n",
    "model.summary()\n",
    "train_test(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "Model: \"res_net18_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cba_100 (CBA)               multiple                  3240      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " res_block_40 (ResBlock)     multiple                  1680      \n",
      "                                                                 \n",
      " res_block_41 (ResBlock)     multiple                  1680      \n",
      "                                                                 \n",
      " res_block_42 (ResBlock)     multiple                  5160      \n",
      "                                                                 \n",
      " res_block_43 (ResBlock)     multiple                  5520      \n",
      "                                                                 \n",
      " res_block_44 (ResBlock)     multiple                  10320     \n",
      "                                                                 \n",
      " res_block_45 (ResBlock)     multiple                  11040     \n",
      "                                                                 \n",
      " res_block_46 (ResBlock)     multiple                  20640     \n",
      "                                                                 \n",
      " res_block_47 (ResBlock)     multiple                  22080     \n",
      "                                                                 \n",
      " global_average_pooling2d_5  multiple                  0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  48100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 129460 (505.70 KB)\n",
      "Trainable params: 120460 (470.55 KB)\n",
      "Non-trainable params: 9000 (35.16 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train GroupConv epoch 1/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:45<00:00,  2.37it/s, lr=0.1000, loss=3.70296]\n",
      "train GroupConv epoch 2/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  3.97it/s, lr=0.1000, loss=3.11310]\n",
      "train GroupConv epoch 3/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.95it/s, lr=0.1000, loss=2.82359]\n",
      "train GroupConv epoch 4/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.96it/s, lr=0.1000, loss=2.63936]\n",
      "train GroupConv epoch 5/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.95it/s, lr=0.1000, loss=2.49180]\n",
      "train GroupConv epoch 6/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  4.00it/s, lr=0.1000, loss=2.36781]\n",
      "train GroupConv epoch 7/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.94it/s, lr=0.1000, loss=2.27117]\n",
      "train GroupConv epoch 8/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.96it/s, lr=0.1000, loss=2.18821]\n",
      "train GroupConv epoch 9/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.95it/s, lr=0.1000, loss=2.11953]\n",
      "train GroupConv epoch 10/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.95it/s, lr=0.1000, loss=2.06353]\n",
      "train GroupConv epoch 11/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  4.00it/s, lr=0.1000, loss=2.00895]\n",
      "train GroupConv epoch 12/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.93it/s, lr=0.1000, loss=1.96067]\n",
      "train GroupConv epoch 13/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.97it/s, lr=0.1000, loss=1.91949]\n",
      "train GroupConv epoch 14/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.94it/s, lr=0.1000, loss=1.88001]\n",
      "train GroupConv epoch 15/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  3.97it/s, lr=0.1000, loss=1.84377]\n",
      "train GroupConv epoch 16/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  3.99it/s, lr=0.1000, loss=1.80910]\n",
      "train GroupConv epoch 17/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.94it/s, lr=0.1000, loss=1.77678]\n",
      "train GroupConv epoch 18/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.96it/s, lr=0.1000, loss=1.75271]\n",
      "train GroupConv epoch 19/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.94it/s, lr=0.1000, loss=1.72870]\n",
      "train GroupConv epoch 20/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.97it/s, lr=0.1000, loss=1.69610]\n",
      "train GroupConv epoch 21/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  4.00it/s, lr=0.1000, loss=1.66926]\n",
      "train GroupConv epoch 22/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.94it/s, lr=0.1000, loss=1.64494]\n",
      "train GroupConv epoch 23/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.96it/s, lr=0.1000, loss=1.61826]\n",
      "train GroupConv epoch 24/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.95it/s, lr=0.1000, loss=1.59431]\n",
      "train GroupConv epoch 25/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:02<00:00,  3.97it/s, lr=0.1000, loss=1.57317]\n",
      "train GroupConv epoch 26/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.97it/s, lr=0.1000, loss=1.54821]\n",
      "train GroupConv epoch 27/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.97it/s, lr=0.1000, loss=1.52840]\n",
      "train GroupConv epoch 28/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.95it/s, lr=0.1000, loss=1.50438]\n",
      "train GroupConv epoch 29/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.96it/s, lr=0.1000, loss=1.48687]\n",
      "train GroupConv epoch 30/30: 100%|\u001b[31m==========\u001b[0m| 250/250 [01:03<00:00,  3.96it/s, lr=0.1000, loss=1.46601]\n",
      "test GroupConv : 100%|\u001b[34m==========\u001b[0m| 50/50 [00:05<00:00,  8.79it/s, correct: 3992/10000, time: 0.05554]\n"
     ]
    }
   ],
   "source": [
    "g=3\n",
    "model = ResNet18(conv, g, oc, nc)\n",
    "print(model(input).shape)\n",
    "model.summary()\n",
    "train_test(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
